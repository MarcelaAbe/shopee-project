# Coleta de Lojas Oficiais da Shopee por Categoria

Este projeto realiza a coleta de **lojas oficiais** da Shopee utilizando a API p√∫blica da plataforma. Os dados s√£o organizados por categoria e exportados em um arquivo CSV com timestamp.

## üì¶ Funcionalidades

- Faz requisi√ß√µes √† API da Shopee por categoria  
- Emula headers de navegador real para evitar bloqueios  
- Traz categorias agrupadas e n√£o agrupadas (como lojas novas)  
- Exporta os dados em formato CSV com timestamp  
- Permite adapta√ß√£o para BigQuery ou outras bases de dados  

## üß∞ Tecnologias Utilizadas

- `axios`: para realizar requisi√ß√µes HTTP  
- `fs`: m√≥dulo nativo para manipula√ß√£o de arquivos (n√£o diretamente usado neste script)  
- `dayjs`: para manipula√ß√£o de datas  
- `csv-writer`: para salvar os dados coletados em CSV  

## üìÇ Estrutura do Script

### 1. Defini√ß√£o de Depend√™ncias

Importa√ß√£o dos m√≥dulos necess√°rios e configura√ß√£o dos headers para simular um navegador real.

### 2. Lista de Categorias

Dicion√°rio com o mapeamento dos IDs de categoria e seus nomes leg√≠veis.

### 3. Coleta de Dados

Loop por todas as categorias, com chamada √† API para cada uma delas, salvando as informa√ß√µes relevantes das lojas.

### 4. Exporta√ß√£o

Cria√ß√£o de um arquivo CSV com o nome `brands_shopee_YYYYMMDD.csv`, contendo todos os dados coletados.

## üìù Campos Exportados

O CSV gerado inclui os seguintes campos:

- `index`  
- `total`  
- `username`  
- `brand_name`  
- `shopid`  
- `logo`  
- `logo_pc`  
- `shop_collection_id`  
- `ctime`  
- `brand_label`  
- `shop_type`  
- `redirect_url`  
- `entity_id`  
- `category_id`  
- `category_name`  
- `url_to`  
- `data_requisicao`  

## ‚úÖ Como Usar

1. Clone este reposit√≥rio  
2. Instale as depend√™ncias:  
   `npm install axios dayjs csv-writer` 
3. Execute o script:  
   `node crawler.js`  
4. O CSV ser√° salvo automaticamente na raiz do projeto com a data do dia no nome.

## üìå Observa√ß√µes

- A categoria com ID "-1" representa a P√°gina Principal, contendo lojas que ainda n√£o foram oficialmente categorizadas.  
- Algumas duplicidades podem surgir. Recomenda-se trat√°-las em p√≥s-processamento conforme necess√°rio.

## üìé Poss√≠veis Extens√µes

- Integra√ß√£o direta com BigQuery  
- Deduplica√ß√£o autom√°tica  
- Agendamento via cron para coleta peri√≥dica

# Espanhol:

# Recolecci√≥n de Tiendas Oficiales de Shopee por Categor√≠a

Este proyecto realiza la recolecci√≥n de **tiendas oficiales** de Shopee utilizando la API p√∫blica de la plataforma. Los datos se organizan por categor√≠a y se exportan en un archivo CSV con timestamp.

## üì¶ Funcionalidades

- Hace solicitudes a la API de Shopee por categor√≠a  
- Emula headers de un navegador real para evitar bloqueos  
- Trae categor√≠as agrupadas y no agrupadas (como tiendas nuevas)  
- Exporta los datos en formato CSV con timestamp  
- Permite adaptaci√≥n para BigQuery u otras bases de datos  

## üß∞ Tecnolog√≠as Utilizadas

- `axios`: para realizar solicitudes HTTP  
- `fs`: m√≥dulo nativo para manipular archivos (no se usa directamente en este script)  
- `dayjs`: para trabajar con fechas  
- `csv-writer`: para guardar los datos recolectados en CSV  

## üìÇ Estructura del Script

### 1. Definici√≥n de Dependencias

Importaci√≥n de los m√≥dulos necesarios y configuraci√≥n de los headers para simular un navegador real.

### 2. Lista de Categor√≠as

Diccionario con el mapeo de los IDs de categor√≠a y sus nombres legibles.

### 3. Recolecci√≥n de Datos

Loop por todas las categor√≠as, haciendo una llamada a la API por cada una y guardando la info relevante de las tiendas.

### 4. Exportaci√≥n

Creaci√≥n de un archivo CSV con el nombre `brands_shopee_YYYYMMDD.csv`, que contiene todos los datos recolectados.

## üìù Campos Exportados

El CSV generado incluye los siguientes campos:

- `index`  
- `total`  
- `username`  
- `brand_name`  
- `shopid`  
- `logo`  
- `logo_pc`  
- `shop_collection_id`  
- `ctime`  
- `brand_label`  
- `shop_type`  
- `redirect_url`  
- `entity_id`  
- `category_id`  
- `category_name`  
- `url_to`  
- `data_requisicao`  

## ‚úÖ C√≥mo Usar

1. Clona este repositorio  
2. Instala las dependencias:  
   `npm install axios dayjs csv-writer` 
3. Ejecuta el script:  
   `node crawler.js`  
4. El CSV ser√° guardado autom√°ticamente en la ra√≠z del proyecto con la fecha del d√≠a en el nombre.

## üìå Notas

- La categor√≠a con ID "-1" representa la P√°gina Principal, que contiene tiendas que a√∫n no han sido categorizadas oficialmente.  
- Pueden surgir duplicados. Se recomienda tratarlos en el post-procesamiento si es necesario.

## üìé Posibles Extensiones

- Integraci√≥n directa con BigQuery  
- Eliminaci√≥n autom√°tica de duplicados  
- Agendamiento con cron para recolectar peri√≥dicamente
