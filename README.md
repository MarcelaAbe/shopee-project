# Recolecci√≥n de Tiendas Oficiales de Shopee por Categor√≠a

Este proyecto automatiza la recolecci√≥n de datos de **tiendas oficiales** de Shopee, segmentadas por categor√≠a, y su posterior procesamiento para normalizaci√≥n, comparaci√≥n com dados do Mercado Livre e carga en BigQuery.

---

## ü§ñ Resumen General

El proceso consta de tres etapas principales:

1. **Crawler en Node.js**  
   Consulta la API p√∫blica de Shopee por categor√≠a para obtener tiendas oficiales. Los datos se recolectan en formato JSON y se exportan a CSV con timestamp.

2. **Tratamiento y Normalizaci√≥n en Python**  
   El CSV generado se limpia, normaliza, se generan IDs √∫nicos (`UNIC_ID`) y se cruza con datos hist√≥ricos en BigQuery.

3. **Matching com Dados do Mercado Livre**  
   Usa modelo BERT e regras heur√≠sticas para comparar os nomes das lojas Shopee com dados de marcas do Mercado Livre, sem depender de uma chave √∫nica.

---

## üì¶ Funcionalidades

### Crawler (Node.js)

- Solicita datos a la API p√∫blica de Shopee por categor√≠a  
- Usa headers simulando navegador real para evitar bloqueos  
- Recupera categor√≠as agrupadas y no agrupadas (tiendas nuevas)  
- Exporta CSV con timestamp  
- Preparado para integraci√≥n con BigQuery o bases externas

### Post-Procesamiento (Python)

- Normaliza nombres de usuario y marca (may√∫sculas, elimina s√≠mbolos y tildes)  
- Detecta y reporta caracteres especiales no deseados  
- Genera `UNIC_ID` alfanum√©rico √∫nico para tiendas nuevas  
- Consulta tabla hist√≥rica en BigQuery para reutilizar IDs existentes  
- Agrega columnas de auditor√≠a de fechas  
- Convierte columna fecha scraping a formato datetime  
- Elimina duplicatas com base en `(USERNAME_SHOPEE, BRAND_NAME_SHOPEE)`  
- Gera chave composta `MATCH_KEY` para rastreabilidade e controle de unicidade  
- Identifica e trata colis√µes de `UNIC_ID` entre marcas distintas  
- Tabela final √© preparada para particionamento por `DATE_SCRAPING`  
- Realiza merge (upsert) dos dados no BigQuery com base no `UNIC_ID`, preservando o hist√≥rico

### Matching com Dados do Mercado Livre

- Usa modelo **BERT (RoBERTa)** para compara√ß√£o sem√¢ntica dos nomes de marca  
- Complementa com **regras heur√≠sticas** para tratar abrevia√ß√µes, kits, varia√ß√µes e ru√≠do  
- N√£o depende de uma chave exata de compara√ß√£o  
- Gera um mapeamento probabil√≠stico entre lojas da Shopee e marcas do Meli  
- Ajuda na consolida√ß√£o e unifica√ß√£o de marcas para an√°lises posteriores  

---

## üß∞ Tecnolog√≠as Utilizadas

- **Node.js:** axios, dayjs, csv-writer  
- **Python:** pandas, re, unicodedata, melitk.bigquery, sentence-transformers  
- **BigQuery:** almacenamiento y consulta de datos finales  
- **Modelos de NLP:** RoBERTa/BERT para correspond√™ncia sem√¢ntica  

---

## üìÇ Estructura y Resumen del C√≥digo

### 1. Crawler (crawler.js)

- Importa m√≥dulos axios, dayjs y csv-writer  
- Define headers HTTP para simular navegador  
- Lista de categor√≠as con IDs y nombres  
- Loop que hace petici√≥n API por cada categor√≠a, guardando tiendas oficiales  
- Exporta datos completos a CSV con fecha en el nombre  

### 2. Post-Procesamiento (Python)

- Carga CSV em DataFrame pandas  
- Normaliza `USERNAME_SHOPEE` y `BRAND_NAME_SHOPEE`  
  - May√∫sculas, remo√ß√£o de sinais, acentos e caracteres duplicados  
  - Substitui√ß√£o de `&` por `E`  
- Gera `UNIC_ID` com base em marcas hist√≥ricas no BigQuery  
- Gera `MATCH_KEY` √∫nico  
- Remove duplicatas  
- Detecta colis√µes de `UNIC_ID`  
- Adiciona colunas de auditoria (`AUD_INS_DTTM`, `AUD_UPD_DTTM`)  
- Realiza merge/upsert com BigQuery  
- Particiona por `DATE_SCRAPING`

### 3. Matching com Mercado Livre (Input_e_match.py)

- Carrega dados do Meli e Shopee  
- Normaliza todos os nomes e marcas  
- Aplica modelo **BERT (RoBERTa)** para gerar embeddings dos nomes  
- Calcula similaridade sem√¢ntica entre marcas Shopee e Meli  
- Complementa com regras (kits, abrevia√ß√µes, quantidades, etc.)  
- Classifica os matches por n√≠vel de confian√ßa (Alto, M√©dio, Baixo)  
- Exporta os matches e atualiza mapeamento para uso posterior  

---

## üìù Campos Exportados

O CSV e a tabela BigQuery cont√™m:

- index  
- total  
- username  
- brand_name  
- shopid  
- logo  
- logo_pc  
- shop_collection_id  
- ctime  
- brand_label  
- shop_type  
- redirect_url  
- entity_id  
- category_id  
- category_name  
- url_to  
- data_requisicao  
- UNIC_ID  
- MATCH_KEY  
- AUD_INS_DTTM  
- AUD_UPD_DTTM  
- DATE_SCRAPING  

---

## ‚úÖ C√≥mo Usar

1. Clonar el repositorio  
2. Instalar dependencias Node.js:  
   ```bash
   npm install axios dayjs csv-writer
   ```
3. Ejecutar el crawler:
   ```bash
   node crawler.js
   ```
4. Executar o tratamento e input de tablas:
   ```bash
   python input_tabla_scraper.py
   ```
5. Verificar os dados na tabela BigQuery resultante
6. Executar o tratamento e matching:
   ```bash
   python input_e_match.py
   ```

---

## üìå Notas

- A categoria com ID `-1` representa a p√°gina principal com lojas n√£o categorizadas  
- Todos os nomes s√£o padronizados antes da compara√ß√£o para aumentar a efic√°cia do matching  
- A combina√ß√£o de BERT + regras garante cobertura mais robusta mesmo sem chave de uni√£o  
- IDs √∫nicos (`UNIC_ID`) s√£o preservados entre execu√ß√µes para garantir rastreabilidade  
